{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMD3WgT0sor777vBZskCMAl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nungdoo/deep-learning-study/blob/main/exercise08_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 합성곱 신경망 구현하기"
      ],
      "metadata": {
        "id": "tqJGxLNF5Pcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**합성곱 신경망의 정방향 계산 구현하기**\n",
        "\n",
        "forpass()\n",
        "- conv2d 함수를 통해 합성곱 수행\n",
        "- 가중치 self.conv_w : 3 X 3 X 1 X 10\n",
        "- 커널마다 1개의 절편, 총 10개의 절편을 더함 self.conv_b\n",
        "- 1차원 배열 self.conv_b는 conv2d() 함수의 결과 마지막 차원에 브로드캐스팅 됨\n",
        "- 풀링으로 줄어든 특성 맵을 배치 차원을 제외한 나머지 차원만 펼침"
      ],
      "metadata": {
        "id": "AOu5-QDmpv35"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY2TdDuaprXB"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def forpass(self, x):\n",
        "  # 3 X 3 합성곱 연산을 수행합니다.\n",
        "  c_out = tf.nn.conv2d(x, self.conv_w, strides=1, padding='SAME') + self.conv_b\n",
        "  # 렐루 함수를 적용합니다.\n",
        "  r_out = tf.nn.relu(c_out)\n",
        "  # 2 X 2 최대 풀링을 적용합니다.\n",
        "  p_out = tf.nn.max_pool2d(r_out, ksize=2, strides=2, padding='VALID')\n",
        "  # 첫 번째 배치 차원을 제외하고 출력을 일렬로 펼칩니다.\n",
        "  f_out = tf.reshape(p_out, [x.shape[0], -1])\n",
        "\n",
        "  # 완전연결층\n",
        "  z1 = tf.matmul(f_out, self.w1) + self.b1          # 첫 번째 층의 선형식 계산\n",
        "  a1 = tf.nn.relu(z1)                               # 활성화 함수 적용\n",
        "  z2 = tf.matmul(a1, self.w2) + self.b2             # 두 번째 층의 선형식 계산\n",
        "  return z2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**합성곱 신경망의 역방향 계산 구현하기**\n",
        "\n",
        "그레이디언트를 구하기 위해 텐서플로의 자동 미분 기능을 사용\n",
        "- 임의의 파이썬 코드나 함수에 대한 미분값 계산 가능\n",
        "- with 블럭으로 tf.GradientTape() 객체가 감시할 코드를 감쌈\n",
        "- tape 객체는 with 블럭 안에서 일어나는 모든 연산을 기록하고 텐서플로 변수인 tf.Variable 객체를 자동으로 추적함"
      ],
      "metadata": {
        "id": "gARPgWswtgvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "x = tf.Variable(np.array([1.0, 2.0, 3.0]))\n",
        "with tf.GradientTape() as tape:\n",
        "  y = x ** 3 + 2 * x + 5\n",
        "\n",
        "# 그레이디언트를 계산합니다.\n",
        "print(tape.gradient(y, x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsq-fE1ft3lS",
        "outputId": "fa2ca64c-8d40-4061-c7db-3b1002c8ec61"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([ 5. 14. 29.], shape=(3,), dtype=float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "자동 미분 기능을 이용하면, backprop() 함수 구현할 필요 없음\n",
        "\n",
        "training()\n",
        "- backprop() 호출하던 부분 제거\n",
        "- softmax_cross_entropy_with_logits() 함수를 이용해 정방향 계산의 결과(z)와 타깃(y)을 기반으로 손실값 계산\n",
        "- softmax_cross_entropy_with_logits() 함수는 배치의 각 샘플에 대한 손실을 반환하므로 reduce_mean()을 이용해 평균 계산\n",
        "\n",
        "그레이디언트 계산하기\n",
        "- tape.gradient() 함수를 이용해 자동으로 계산\n",
        "- optimizer.apply_gradients() 함수를 이용해 가중치 업데이트\n"
      ],
      "metadata": {
        "id": "FFQswEaWuvLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training(self, x, y):\n",
        "  m = len(x)\n",
        "  with tf.GradientTape() as tape:\n",
        "    # 정방향 계산 수행\n",
        "    z = self.forpass(x)\n",
        "    # 손실 계산\n",
        "    loss = tf.nn.softmax_cross_entropy_with_logits(y, z)\n",
        "    loss = tf.reduce_mean(loss)\n",
        "\n",
        "    weights_list = [self.conv_w, self.conv_b, self.w1, self.b1, self.w2, self.b2]\n",
        "    # 가중치에 대한 그레이디언트를 계산합니다.\n",
        "    grads = tape.gradient(loss, weights_list)\n",
        "    # 가중치를 업데이트합니다.\n",
        "    self.optimizer.apply_gradients(zip(grads, weights_list))"
      ],
      "metadata": {
        "id": "uYHB8hV9vS57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**옵티마이저 객체를 만들어 가중치 초기화하기**\n",
        "\n",
        "fit()\n",
        "- 확률적 경사 하강법을 사용하는 옵티마이저 생성"
      ],
      "metadata": {
        "id": "D4PIHjdgx1nn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
        "    self.init_weights(x.shape, y.shape[1])                     # 은닉층과 출력층의 가중치 초기화\n",
        "    self.optimizer = tf.optimizers.SGD(learning_rate=self.lr)\n",
        "\n",
        "    for i in range(epochs):\n",
        "      loss = 0\n",
        "      print('에포크', i, end=' ')\n",
        "      batch_losses = []\n",
        "      for x_batch, y_batch in self.gen_batch(x, y):               # 미니 배치 순환\n",
        "        print('.', end='')\n",
        "        self.training(x_batch, y_batch)\n",
        "        # 배치 손실을 기록합니다.\n",
        "        batch_losses.append(self.get_loss(x_batch, y_batch))\n",
        "      print( )\n",
        "      # 배치 손실 평균을 내어 훈련 손실값으로 저장합니다.\n",
        "      self.losses.append(np.mean(batch_losses))\n",
        "      # 검증 세트에 대한 손실을 계산합니다.\n",
        "      self.val_losses.append(self.get_loss(x_val, y_val))"
      ],
      "metadata": {
        "id": "KoYmEIZgyLbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "init_weights()\n",
        "- glorot_uniform() 함수를 이용해 가중치 초기화\n",
        "- 자동 미분 기능을 사용하기 위해 가중치를 tf.Variable() 함수로 만들어야 함\n",
        "\n",
        "글로럿 초기화 방식\n",
        "- 신경망 모델이 커지만 손실 함수도 복잡해져 출발점에 따라 결과가 달라질 수 있음\n",
        "- 가중치를 잘못 초기화하면 전역 최적점이 아닌, 지역 최적점을 찾음\n",
        "- glorot_uniform() 함수로 만든 객체에 필요한 가중치 크기를 전달"
      ],
      "metadata": {
        "id": "aZiaZxv0zpZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(self, input_shape, n_classes):\n",
        "  g = tf.initializers.glorot_uniform()\n",
        "  self.conv_w = tf.Variable(g((3, 3, 1, self.n_kernels)))\n",
        "  self.conv_b = tf.Variable(np.zeros(self.n_kernels), dtype=float)\n",
        "  n_features = 14 * 14 * self.n_kernels\n",
        "  self.w1 = tf.Variable(g((n_features, self.units)))\n",
        "  self.b1 = tf.Variable(np.zeros(self.units), dtype=float)\n",
        "  self.w2 = tf.Variable(g((self.units, n_classes)))         # (은닉층의 크기, 클래스의 크기)\n",
        "  self.b2 = tf.Variable(np.zeros(n_classes), dtype=float)   # 클래스의 크기"
      ],
      "metadata": {
        "id": "jFFofVAuz0QG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionNetwork:\n",
        "\n",
        "  def __init__(self, n_kernels=10, units=10, batch_size=32, learning_rate=0.1):\n",
        "    self.n_kernels = n_kernels  # 합성곱의 커널 개수\n",
        "    self.kernel_size = 3        # 커널 크기\n",
        "    self.optimizer = None       # 옵티마이저\n",
        "    self.conv_w = None          # 합성곱층의 가중치\n",
        "    self.conv_b = None          # 합성곱층의 절편\n",
        "\n",
        "    self.units = units      # 은닉층의 뉴런 개수\n",
        "    self.w1 = None          # 은닉층의 가중치\n",
        "    self.b1 = None          # 은닉층의 절편\n",
        "    self.w2 = None          # 출력층의 가중치\n",
        "    self.b2 = None          # 출력층의 절편\n",
        "    self.a1 = None          # 은닉층의 활성화 출력, 역방향 계산 시 필요하여 저장\n",
        "    self.losses = []        # 훈련 손실\n",
        "    self.val_losses = []    # 검증 손실\n",
        "    self.lr = learning_rate # 학습률\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "  def forpass(self, x):\n",
        "    # 3 X 3 합성곱 연산을 수행합니다.\n",
        "    c_out = tf.nn.conv2d(x, self.conv_w, strides=1, padding='SAME') + self.conv_b\n",
        "    # 렐루 함수를 적용합니다.\n",
        "    r_out = tf.nn.relu(c_out)\n",
        "    # 2 X 2 최대 풀링을 적용합니다.\n",
        "    p_out = tf.nn.max_pool2d(r_out, ksize=2, strides=2, padding='VALID')\n",
        "    # 첫 번째 배치 차원을 제외하고 출력을 일렬로 펼칩니다.\n",
        "    f_out = tf.reshape(p_out, [x.shape[0], -1])\n",
        "\n",
        "    # 완전연결층\n",
        "    z1 = tf.matmul(f_out, self.w1) + self.b1          # 첫 번째 층의 선형식 계산\n",
        "    a1 = tf.nn.relu(z1)                               # 활성화 함수 적용\n",
        "    z2 = tf.matmul(a1, self.w2) + self.b2             # 두 번째 층의 선형식 계산\n",
        "    return z2\n",
        "\n",
        "  def init_weights(self, input_shape, n_classes):\n",
        "    g = tf.initializers.glorot_uniform()\n",
        "    self.conv_w = tf.Variable(g((3, 3, 1, self.n_kernels)))\n",
        "    self.conv_b = tf.Variable(np.zeros(self.n_kernels), dtype=float)\n",
        "    n_features = 14 * 14 * self.n_kernels\n",
        "    self.w1 = tf.Variable(g((n_features, self.units)))\n",
        "    self.b1 = tf.Variable(np.zeros(self.units), dtype=float)\n",
        "    self.w2 = tf.Variable(g((self.units, n_classes)))         # (은닉층의 크기, 클래스의 크기)\n",
        "    self.b2 = tf.Variable(np.zeros(n_classes), dtype=float)   # 클래스의 크기\n",
        "\n",
        "  def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
        "    self.init_weights(x.shape, y.shape[1])                     # 은닉층과 출력층의 가중치 초기화\n",
        "    self.optimizer = tf.optimizers.SGD(learning_rate=self.lr)\n",
        "\n",
        "    for i in range(epochs):\n",
        "      loss = 0\n",
        "      print('에포크', i, end=' ')\n",
        "      batch_losses = []\n",
        "      for x_batch, y_batch in self.gen_batch(x, y):               # 미니 배치 순환\n",
        "        print('.', end='')\n",
        "        self.training(x_batch, y_batch)\n",
        "        # 배치 손실을 기록합니다.\n",
        "        batch_losses.append(self.get_loss(x_batch, y_batch))\n",
        "      print( )\n",
        "      # 배치 손실 평균을 내어 훈련 손실값으로 저장합니다.\n",
        "      self.losses.append(np.mean(batch_losses))\n",
        "      # 검증 세트에 대한 손실을 계산합니다.\n",
        "      self.val_losses.append(self.get_loss(x_val, y_val))\n",
        "\n",
        "  def gen_batch(self, x, y):\n",
        "    bins = len(x) // self.batch_size\n",
        "    indexes = np.random.permutation(np.arange(len(x)))\n",
        "    x = x[indexes]\n",
        "    y = y[indexes]\n",
        "    for i in range(bins):\n",
        "      start = self.batch_size * i\n",
        "      end = self.batch_size * (i + 1)\n",
        "      yield x[start:end], y[start:end]\n",
        "\n",
        "  def training(self, x, y):\n",
        "    m = len(x)\n",
        "    with tf.GradientTape() as tape:\n",
        "      # 정방향 계산 수행\n",
        "      z = self.forpass(x)\n",
        "      # 손실 계산\n",
        "      loss = tf.nn.softmax_cross_entropy_with_logits(y, z)\n",
        "      loss = tf.reduce_mean(loss)\n",
        "\n",
        "    weights_list = [self.conv_w, self.conv_b, self.w1, self.b1, self.w2, self.b2]\n",
        "    # 가중치에 대한 그레이디언트를 계산합니다.\n",
        "    grads = tape.gradient(loss, weights_list)\n",
        "    # 가중치를 업데이트합니다.\n",
        "    self.optimizer.apply_gradients(zip(grads, weights_list))  \n",
        "\n",
        "  def predict(self, x):\n",
        "    z = self.forpass(x)\n",
        "    # 가장 큰 값의 인덱스를 반환합니다.\n",
        "    return np.argmax(z.numpy(), axis=1) # 정방향 계산으로 얻은 출력값인 Tensor 객체를 넘파이 배열로 바꿈\n",
        "\n",
        "  def score(self, x, y):\n",
        "    # 예측과 타깃 열 벡터를 비교하여 True의 비율을 반환합니다.\n",
        "    return np.mean(self.predict(x) == np.argmax(y, axis=1))\n",
        "\n",
        "  def get_loss(self, x, y):\n",
        "    # 정방향 계산을 수행합니다.\n",
        "    z = self.forpass(x)\n",
        "    # 손실을 계산하여 저장합니다.\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, z))\n",
        "    return loss.numpy()"
      ],
      "metadata": {
        "id": "gcpxF2h12tW4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 합성곱 신경망 훈련하기"
      ],
      "metadata": {
        "id": "IaV_aKu25So-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 세트 불러오기\n",
        "(x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# 훈련 세트와 검증 세트로 나누기\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all, test_size=0.2, random_state=42)\n",
        "\n",
        "# 타깃을 원-핫 인코딩으로 변환\n",
        "y_train_encoded = tf.keras.utils.to_categorical(y_train)\n",
        "y_val_encoded = tf.keras.utils.to_categorical(y_val)\n",
        "\n",
        "# 입력 데이터 준비하기 (일렬로 펼칠 필요 없음, 컬러 채널만 추가)\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_val = x_val.reshape(-1, 28, 28, 1)\n",
        "print(x_train.shape)\n",
        "\n",
        "# 입력 데이터 표준화 전처리\n",
        "x_train = x_train / 255\n",
        "x_val = x_val / 255"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAWHDODr5ZaV",
        "outputId": "3888d08d-333b-41c2-f819-6519490dcc45"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(48000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "모델 훈련하기\n",
        "- 합성곱 커널 10개\n",
        "- 완전 연결층의 뉴런 100개\n",
        "- 배치 크기 128개\n",
        "- 학습률 0.01"
      ],
      "metadata": {
        "id": "LDd5078l5ZAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cn = ConvolutionNetwork(n_kernels=10, units=100, batch_size=128, learning_rate=0.01)\n",
        "cn.fit(x_train, y_train_encoded, x_val=x_val, y_val=y_val_encoded, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D763RBrg6fA9",
        "outputId": "ffcccbec-d7a2-4538-ff02-caabe49369df"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크 0 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 1 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 2 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 3 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 4 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 5 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 6 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 7 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 8 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 9 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 10 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 11 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 12 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 13 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 14 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 15 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 16 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 17 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 18 .......................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 19 .......................................................................................................................................................................................................................................................................................................................................................................................\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련, 검증 손실 그래프 & 검증 세트 정확도 확인"
      ],
      "metadata": {
        "id": "Tcm4gh4e6-E-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(cn.losses)\n",
        "plt.plot(cn.val_losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('iteration')\n",
        "plt.legend(['train_loss', 'val_loss'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "vXccujc57C9K",
        "outputId": "e74ede57-a19d-4e94-fc41-e17a3389b832"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cn.score(x_val, y_val_encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b5h6HuI9RP4",
        "outputId": "3901be65-0822-41e7-bba7-c530d4ea1d4a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.867"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}