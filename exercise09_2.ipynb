{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPTHxKDB8u3mgzUhKCnwt49",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nungdoo/deep-learning-study/blob/main/exercise09_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 준비"
      ],
      "metadata": {
        "id": "tTBKh5k920zp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "훈련 세트와 검증 세트 준비\n",
        "- IMDB 영화 리뷰 데이터\n",
        "- 리뷰가 긍정적인지 부정적인지 판별해보기 (이진 분류)"
      ],
      "metadata": {
        "id": "nGziSaQA33Xt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg0DeDi230Jl",
        "outputId": "38d06e67-1659-4d4d-bdb7-7faf2804834a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "(25000,) (25000,)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "# skip_top : 가장 많이 등장한 단어 중 건너뛸 단어의 개수 지정\n",
        "# 가장 흔한 단어 20개는 제외 (크게 의미 없어서)\n",
        "# num_words : 훈련에 사용할 단어의 개수 지정\n",
        "# 메모리 절약을 위해 100 지정\n",
        "(x_train_all, y_train_all), (x_test, y_test) = imdb.load_data(skip_top=20, num_words=100)\n",
        "\n",
        "# 넘파이 배열의 리스트로 전달됨\n",
        "print(x_train_all.shape, y_train_all.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 세트의 샘플이 정수로 저장되어 있음\n",
        "# 영단어를 고유한 정수에 일대일 대응한 것\n",
        "# 2는 매핑한 어휘 사전에 없는 단어 (100개의 단어만 선택하여 없는 단어가 많음)\n",
        "print(x_train_all[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKwZLkWy3slT",
        "outputId": "cd058115-cadc-4c76-928d-a8aa1dd82c74"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2, 2, 22, 2, 43, 2, 2, 2, 2, 65, 2, 2, 66, 2, 2, 2, 36, 2, 2, 25, 2, 43, 2, 2, 50, 2, 2, 2, 35, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 39, 2, 2, 2, 2, 2, 2, 38, 2, 2, 2, 2, 50, 2, 2, 2, 2, 2, 2, 22, 2, 2, 2, 2, 2, 22, 71, 87, 2, 2, 43, 2, 38, 76, 2, 2, 2, 2, 22, 2, 2, 2, 2, 2, 2, 2, 2, 2, 62, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 66, 2, 33, 2, 2, 2, 2, 38, 2, 2, 25, 2, 51, 36, 2, 48, 25, 2, 33, 2, 22, 2, 2, 28, 77, 52, 2, 2, 2, 2, 82, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 36, 71, 43, 2, 2, 26, 2, 2, 46, 2, 2, 2, 2, 2, 2, 88, 2, 2, 2, 2, 98, 32, 2, 56, 26, 2, 2, 2, 2, 2, 2, 2, 22, 21, 2, 2, 26, 2, 2, 2, 30, 2, 2, 51, 36, 28, 2, 92, 25, 2, 2, 2, 65, 2, 38, 2, 88, 2, 2, 2, 2, 2, 2, 2, 2, 32, 2, 2, 2, 2, 2, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 의미 없는 데이터 제외\n",
        "# 0 : 패딩\n",
        "# 1 : 글의 시작\n",
        "# 2 : 없는 단어\n",
        "for i in range(len(x_train_all)):\n",
        "  x_train_all[i] = [w for w in x_train_all[i] if w > 2]\n",
        "\n",
        "print(x_train_all[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWeIGF3d4Ig9",
        "outputId": "4f6b61f4-0303-441f-b39c-ef3c41ae156a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[22, 43, 65, 66, 36, 25, 43, 50, 35, 39, 38, 50, 22, 22, 71, 87, 43, 38, 76, 22, 62, 66, 33, 38, 25, 51, 36, 48, 25, 33, 22, 28, 77, 52, 82, 36, 71, 43, 26, 46, 88, 98, 32, 56, 26, 22, 21, 26, 30, 51, 36, 28, 92, 25, 65, 38, 88, 32, 32]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 숫자를 영단어와 매핑해보기 위해 어휘 사전 내려받기\n",
        "# movie는 17과 매핑됨\n",
        "word_to_index = imdb.get_word_index()\n",
        "word_to_index['movie']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2RA2DDq4jnc",
        "outputId": "5854bdf6-c9a4-41ff-84a5-4b94b059165e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 세트의 정수를 영단어로 변환\n",
        "# 3 이상의 정수가 영단어를 의미하므로, 3을 빼고 인덱스로 사용\n",
        "index_to_word = {word_to_index[k]: k for k in word_to_index}\n",
        "\n",
        "for w in x_train_all[0]:\n",
        "  print(index_to_word[w-3], end=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdb0cd6n48pf",
        "outputId": "672d1150-b33c-4193-9fb2-d0e5da96b9a8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "film just story really they you just there an from so there film film were great just so much film would really at so you what they if you at film have been good also they were just are out because them all up are film but are be what they have don't you story so because all all "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 훈련 샘플의 길이 확인\n",
        "# 각 리뷰의 길이가 달라 샘플의 길이가 다름\n",
        "# 샘플의 길이가 다르면 모델을 제대로 훈련시킬 수 없음\n",
        "print(len(x_train_all[0]), len(x_train_all[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUKHzrKL5UDo",
        "outputId": "02f7f2aa-e22d-4ac2-cff5-b5efed5bef99"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 타깃 데이터 확인\n",
        "# 이진 분류 문제이므로 1, 0으로 이루어짐\n",
        "print(y_train_all[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkKB53IV5vbj",
        "outputId": "09ed36e5-30f1-44a9-860d-67a52a2dd22e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 0 0 1 0 0 1 0 1 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 세트 준비\n",
        "# 훈련 세트 : 20000개, 검증 세트 5000개\n",
        "np.random.seed(42)\n",
        "random_index = np.random.permutation(25000)\n",
        "\n",
        "x_train = x_train_all[random_index[:20000]]\n",
        "y_train = y_train_all[random_index[:20000]]\n",
        "x_val = x_train_all[random_index[20000:]]\n",
        "y_val = y_train_all[random_index[20000:]]"
      ],
      "metadata": {
        "id": "2xp6sUvn55U_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플의 길이 맞추기\n",
        "- 맞추려는 길이보다 짧을 땐 앞에 0을 채움\n",
        "- 뒤에 0이 추가되면 모델의 성능이 좋지 않기 때문\n",
        "- 맞추려는 길이보다 길 땐 앞의 단어를 버림\n",
        "- 뒤에 나타나는 단어가 의미있을 가능성이 높기 때문"
      ],
      "metadata": {
        "id": "5TA1FXwf4vUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import sequence\n",
        "\n",
        "# 기준 길이 : 100\n",
        "maxlen = 100\n",
        "\n",
        "# 길이 맞추기\n",
        "x_train_seq = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_val_seq = sequence.pad_sequences(x_val, maxlen=maxlen)\n",
        "\n",
        "print(x_train_seq.shape, x_val_seq.shape)\n",
        "\n",
        "print(x_train_seq[0])"
      ],
      "metadata": {
        "id": "EsJax1WU5Qe6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449cdc6d-f0f9-4adf-c18f-b2c63473377b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 100) (5000, 100)\n",
            "[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0 35 40 27 28 40 22 83 31 85 45\n",
            " 24 23 31 70 31 76 30 98 32 22 28 51 75 56 30 33 97 53 38 46 53 74 31 35\n",
            " 23 34 22 58]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "샘플 원-핫 인코딩하기\n",
        "- 샘플을 100차원으로 원-핫 인코딩"
      ],
      "metadata": {
        "id": "zISjA0N15p8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "x_train_onehot = to_categorical(x_train_seq)\n",
        "x_val_onehot = to_categorical(x_val_seq)\n",
        "\n",
        "print(x_train_onehot.shape)\n",
        "\n",
        "print(x_train_onehot.nbytes)"
      ],
      "metadata": {
        "id": "t0XbJUAa5z2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00af35dc-3d66-4020-8c74-2e52db1d43dc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 100, 100)\n",
            "800000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 순환 신경망 클래스 구현하기"
      ],
      "metadata": {
        "id": "qVQoH7WY70lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "class RecurrentNetwork:\n",
        "\n",
        "  # 은닉층의 개수 대신 셀 개수를 입력 받음\n",
        "  # 셀에 필요한 가중치 w1h, w1x 선언\n",
        "  # 타임 스텝을 거슬러 그레이디언트를 전파하기 위해, 활성화 출력을 모두 갖고 있을 h 선언\n",
        "  def __init__(self, n_cells=10, batch_size=32, learning_rate=0.1):\n",
        "    self.n_cells = n_cells\n",
        "    self.batch_size = batch_size\n",
        "    self.w1h = None\n",
        "    self.w1x = None\n",
        "    self.b1 = None\n",
        "    self.w2 = None\n",
        "    self.b2 = None\n",
        "    self.h = None\n",
        "    self.losses = []\n",
        "    self.val_losses = []\n",
        "    self.lr = learning_rate\n",
        "\n",
        "  # 직교 행렬 초기화 : 순환 셀에서 은닉 상태를 위한 가중치가 반복해서 곱해질 때 너무 커지거나 작아지지 않게 해줌\n",
        "  def init_weights(self, n_features, n_classes):\n",
        "    orth_init = tf.initializers.Orthogonal()\n",
        "    glorot_init = tf.initializers.GlorotUniform()\n",
        "\n",
        "    self.w1h = orth_init((self.n_cells, self.n_cells)).numpy()      # (셀 개수, 셀 개수)\n",
        "    self.w1x = glorot_init((n_features, self.n_cells)).numpy()      # (특성 개수, 셀 개수)\n",
        "    self.b1 = np.zeros(self.n_cells)                                # 은닉층의 크기\n",
        "    self.w2 = glorot_init((self.n_cells, n_classes)).numpy()        # (셀 개수, 클래스 개수)\n",
        "    self.b2 = np.zeros(n_classes)\n",
        "\n",
        "  # 정방향 계산\n",
        "  def forpass(self, x):\n",
        "    # 각 타임 스텝의 은닉 상태를 저장하기 위한 h 초기화\n",
        "    # 첫 번째 타임 스텝의 이전 은닉 상태는 없으므로, 0으로 채워진 배열로 초기화\n",
        "    self.h = [np.zeros((x.shape[0], self.n_cells))]               # (샘플 개수, 셀 개수)\n",
        "\n",
        "    # 입력 x의 첫 번째 배치 차원과 두 번째 타임 스텝 차원을 바꿉니다.\n",
        "    # 미니 배치 안에 있는 모든 샘플의 첫 번째 타임 스텝을 한 번에 처리하고 그 다음 타임 스텝을 한번에 처리해야 하므로\n",
        "    seq = np.swapaxes(x, 0, 1)\n",
        "\n",
        "    # 각 샘플의 모든 타임 스텝에 대한 정방향 계산\n",
        "    # 계산된 은닉 상태를 h에 순서대로 추가함\n",
        "    for x in seq:\n",
        "      z1 = np.dot(x, self.w1x) + np.dot(self.h[-1], self.w1h) + self.b1\n",
        "      h = np.tanh(z1)                     # 활성화 함수를 적용합니다.\n",
        "      self.h.append(h)                    # 역전파를 위해 은닉 상태를 저장합니다.\n",
        "      z2 = np.dot(h, self.w2) + self.b2   # 출력층의 선형식을 계산합니다.\n",
        "    return z2\n",
        "\n",
        "  # 역방향 계산\n",
        "  def backprop(self, x, err):\n",
        "    m = len(x)    # 샘플 개수\n",
        "\n",
        "    # 출력층의 가중치와 절편에 대한 그레이디언트를 계산합니다.\n",
        "    w2_grad = np.dot(self.h[-1].T, err) / m\n",
        "    b2_grad = np.sum(err) / m\n",
        "\n",
        "    # 모든 샘플의 타임 스텝을 한 번에 처리하기 위해 배치 차원과 타임 스텝 차원을 바꿈\n",
        "    seq = np.swapaxes(x, 0, 1)\n",
        "\n",
        "    w1h_grad = w1x_grad = b1_grad = 0\n",
        "    # err_to_cell : Z1에 대하여 손실 함수를 미분한 도함수의 결괏값\n",
        "    err_to_cell = np.dot(err, self.w2.T) * (1 - self.h[-1] ** 2)\n",
        "    # 모든 타임 스텝을 거슬러 가면서 그레이디언트를 전파합니다.\n",
        "    # 타임 스텝을 거슬러 올라가며 그레이디언트를 전파할 때 동일한 가중치를 반복적으로 곱해, 이로 인해 그레이디언트가 너무 커지거나 작아지는 문제가 발생\n",
        "    # 이를 방지하기 위해 그레이디언트를 전파하는 타임 스텝의 수(TBPTT)를 제한 : 10\n",
        "    for x, h in zip(seq[::-1][:10], self.h[:-1][::-1][:10]):\n",
        "      w1h_grad += np.dot(h.T, err_to_cell)\n",
        "      w1x_grad += np.dot(x.T, err_to_cell)\n",
        "      b1_grad += np.sum(err_to_cell, axis=0)\n",
        "      err_to_cell = np.dot(err_to_cell, self.w1h) * (1 - h ** 2)\n",
        "\n",
        "    w1h_grad /= m\n",
        "    w1x_grad /= m\n",
        "    b1_grad /= m\n",
        "\n",
        "    return w1h_grad, w1x_grad, b1_grad, w2_grad, b2_grad\n",
        "\n",
        "  def sigmoid(self, z):\n",
        "    z = np.clip(z, -100, None)    # 안전한 계산을 위해 clip\n",
        "    a = 1 / (1 + np.exp(-z))      # 시그모이드 계산\n",
        "    return z\n",
        "\n",
        "  def fit(self, x, y, epochs=100, x_val=None, y_val=None):\n",
        "    y = y.reshape(-1, 1)                                  # 타깃을 열 벡터로 바꿉니다.\n",
        "    y_val = y_val.reshape(-1, 1)                          # 검증용 타깃을 열 벡터로 바꿉니다.\n",
        "    self.init_weights(x.shape[2], y.shape[1])             # 은닉층과 출력층의 가중치 초기화\n",
        "    np.random.seed(42)\n",
        "\n",
        "    for i in range(epochs):\n",
        "      print('에포크', i, end=' ')\n",
        "      batch_losses = []\n",
        "      # 미니 배치 순환\n",
        "      for x_batch, y_batch in self.gen_batch(x, y):\n",
        "        print('.', end='')\n",
        "        a = self.training(x_batch, y_batch)\n",
        "        a = np.clip(a, 1e-10, 1-1e-10)                                    # 안전한 로그 계산을 위해 클리핑합니다.\n",
        "        loss = np.mean(-(y_batch*np.log(a) + (1-y_batch)*np.log(1-a)))    # 로그 손실과 규제 손실을 더하여 리스트에 추가합니다.\n",
        "        batch_losses.append(loss)\n",
        "      print()\n",
        "      self.losses.append(np.mean(batch_losses))           # 에포크마다 평균 손실을 저장\n",
        "      self.update_val_loss(x_val, y_val)                  # 검증 세트에 대한 손실을 계산합니다.\n",
        "\n",
        "  # 미치 배치 제너레이터\n",
        "  def gen_batch(self, x, y):\n",
        "    length = len(x)\n",
        "    bins = length // self.batch_size      # 미니 배치 횟수\n",
        "    if length % self.batch_size:\n",
        "      bins += 1\n",
        "    indexes = np.random.permutation(np.arange(len(x)))\n",
        "    x = x[indexes]\n",
        "    y = y[indexes]\n",
        "    for i in range(bins):\n",
        "      start = self.batch_size * i\n",
        "      end = self.batch_size * (i + 1)\n",
        "      yield x[start:end], y[start:end]    # batch_size만큼 슬라이싱하여 반환\n",
        "\n",
        "  def training(self, x, y):\n",
        "    m = len(x)                                          # 샘플 개수\n",
        "    z = self.forpass(x)                                 # 정방향 계산을 수행합니다.\n",
        "    a = self.sigmoid(z)                                 # 활성화 함수를 적용합니다.\n",
        "    err = -(y - a)                                      # 오차를 계산합니다.\n",
        "    \n",
        "    # 오차를 역전파하여 그레이디언트를 계산합니다.\n",
        "    w1h_grad, w1x_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\n",
        "\n",
        "    # 셀의 가중치와 절편을 업데이트합니다.\n",
        "    self.w1h -= self.lr * w1h_grad\n",
        "    self.w1x -= self.lr * w1x_grad\n",
        "    self.b1 -= self.lr * b1_grad\n",
        "\n",
        "    # 출력층의 가중치와 절편을 업데이트합니다.\n",
        "    self.w2 -= self.lr * w2_grad\n",
        "    self.b2 -= self.lr * b2_grad\n",
        "\n",
        "    # 출력층의 활성화 출력 a를 반환합니다.\n",
        "    return a\n",
        "\n",
        "  def predict(self, x):\n",
        "    z = self.forpass(x)                   # 정방향 계산\n",
        "    return z > 0                          # 스텝 함수 적용\n",
        "\n",
        "  def score(self, x, y):\n",
        "    # 예측과 타깃 열 벡터를 비교하여 True의 비율을 반환합니다.\n",
        "    return np.mean(self.predict(x) == y.reshape(-1, 1))\n",
        "\n",
        "  def update_val_loss(self, x_val, y_val):\n",
        "    z = self.forpass(x_val)               # 정방향 계산\n",
        "    a = self.sigmoid(z)                   # 활성화 함수 적용\n",
        "    a = np.clip(a, 1e-10, 1-1e-10)        # 출력값 클리핑\n",
        "    val_loss = np.mean(-(y_val*np.log(a) + (1-y_val)*np.log(1-a)))\n",
        "    self.val_losses.append(val_loss)"
      ],
      "metadata": {
        "id": "OJpG0exj8OIQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 순환 신경망 모델 훈련시키기"
      ],
      "metadata": {
        "id": "OXJZFmv-JxwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rn = RecurrentNetwork(n_cells=32, batch_size=32, learning_rate=0.01)\n",
        "rn.fit(x_train_onehot, y_train, epochs=20, x_val=x_val_onehot, y_val=y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deiFQ-zdJxad",
        "outputId": "25051e24-db63-40b4-cf7d-6feced5c1fad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크 0 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 1 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 2 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 3 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 4 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 5 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 6 .................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "에포크 7 ............................................................................................................................................................................."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 손실 그래프 그리기\n",
        "plt.plot(rn.losses)\n",
        "plt.plot(rn.val_losses)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "pdRsn3UfKbha",
        "outputId": "bc892339-8f57-4245-919e-99985a7f47e2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 세트 정확도 평가하기\n",
        "rn.score(x_val_onehot, y_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YwnGTqjrKizA",
        "outputId": "4ff02094-e2df-49ce-f093-b1487559d00e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4952"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}